---
title: "TCC prévia"
format: html
jupyter: python3

---

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('ggplot')

import nltk
```

```{python}
df = pd.read_csv('Reviews.csv')
print(df.shape)
```

```{python}
# Filtrar apenas as notas desejadas (1, 2, 4, 5)
df = df[df['Score'].isin([1, 2, 4, 5])]

df = (
    df[df['Score'].isin([1, 2, 4, 5])]  # Filtra apenas Scores 1, 2, 4, 5
    .groupby('Score', group_keys=False)   # Agrupa por Score
    .sample(n=5000, random_state=42)     # Pega 5000 de cada grupo
    .sample(frac=1, random_state=42)     # Embaralha (opcional)
    .reset_index(drop=True)              # Remove o índice antigo
)

# Verificação
print(df['Score'].value_counts().sort_index())
```

### NLTK Básico

```{python}
example = df['Text'][50]
print(example)
```

```{python}
tokens = nltk.word_tokenize(example)
print(tokens[:10])
tagged = nltk.pos_tag(tokens)
print(tagged[:10])
entities = nltk.chunk.ne_chunk(tagged)
entities.pprint()
```

## VADER Sentiment Score

Usando VADER (Valence Aware Dictionary and Sentiment Reasoner); um approach bag-of-words, ou seja, 'Stop words' são removidas e cada palavra recebe um score que é somado ao total.

```{python}
from nltk.sentiment import SentimentIntensityAnalyzer
from tqdm.notebook import tqdm

sia = SentimentIntensityAnalyzer()
```

Importante notar que o método está treinado para palavras em inglês, portanto os exemplos também são usados em inglês:

```{python}
sia.polarity_scores('I am very happy!')
```

```{python}
sia.polarity_scores('This is the worst thing ever dude')
```

```{python}
sia.polarity_scores(example)
```

Vamos rodar o teste de polaridade para o dataset completo

```{python}
res = {}
for i, row in tqdm(df.iterrows(), total = len(df)):
    text = row['Text']
    myid = row['Id']
    res[myid] = sia.polarity_scores(text)
```

```{python}
vaders = pd.DataFrame(res).T

vaders = vaders.reset_index().rename(columns = {'index': 'Id'})

vaders['Id'] = vaders['Id'].astype(str)
df['Id'] = df['Id'].astype(str)

vaders = vaders.merge(df, how = 'left', on = 'Id')

# Sentiment score e metadados
vaders.head()
```

#### Plotando alguns resultados do VADER

```{python}
sx = sns.barplot(data=vaders, x = 'Score', y = 'compound')
sx.set_title('Compound Score dos Reviews da Amazon')
plt.show()
```

```{python}
fig, axs=plt.subplots(1,3, figsize = (12,3))

sns.barplot(data=vaders, x = 'Score', y = 'pos', ax = axs[0])
sns.barplot(data=vaders, x='Score', y='neu', ax=axs[1])
sns.barplot(data=vaders, x='Score', y='neg', ax=axs[2])
axs[0].set_title('Positivo')
axs[1].set_title('Neutro')
axs[2].set_title('Negativo')
plt.tight_layout()
plt.show()
```

## Usando o modelo pré-treinado Roberta

Baseado em transformers e deep learning, nao é bag of words.

Importante comparar os modelos, pois nesse caso o Roberta é capaz de assimilar não somente as palavras de forma individual, mas também a relação entre elas.

```{python}
from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from scipy.special import softmax
```

```{python}
import torch
print(torch.cuda.is_available())

print(torch.__version__)
print(torch.version.cuda)
```

```{python}
MODEL = f"cardiffnlp/twitter-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)
```

```{python}
# resultados do modelo VADER no exemplo setado acima
print(example)
sia.polarity_scores(example)
```

```{python}
# Rodando agora o modelo Roberta

encoded_text = tokenizer(example, return_tensors='pt')
output = model(**encoded_text)
scores = output[0][0].detach().numpy()
scores = softmax(scores)
scores_dict = {
    'roberta_neg' : scores[0],
    'roberta_neu' : scores[1],
    'roberta_pos' : scores[2]
}
print(scores_dict)
```

É facilmente detectável uma precisão maior em relação ao comentário

```{python}
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(device)

def polarity_scores_roberta(example):
    encoded_text = tokenizer(example, return_tensors='pt').to(device)
    output = model(**encoded_text)
    scores = output[0][0].detach().cpu().numpy()
    scores = softmax(scores)
    return {
        'roberta_neg': scores[0],
        'roberta_neu': scores[1],
        'roberta_pos': scores[2]
    }
    return scores_dict

res = {}
for i, row in tqdm(df.iterrows(), total=len(df)):
    try:
        text = row['Text']
        myid = row['Id']
        vader_result = sia.polarity_scores(text)
        vader_result_rename = {}
        for key, value in vader_result.items():
            vader_result_rename[f"vader_{key}"] = value
        roberta_result = polarity_scores_roberta(text)
        both = {**vader_result_rename, **roberta_result}
        res[myid] = both
    except RuntimeError:
        print(f'Broke for id {myid}')
```

```{python}
results_df = pd.DataFrame(res).T
results_df = results_df.reset_index().rename(columns={'index': 'Id'})
results_df = results_df.merge(df, how='left')
```

```{python}
results_df.columns
```

## Combinando e comparando os resultados

```{python}
sns.pairplot(data=results_df,
             vars=['vader_neg', 'vader_neu', 'vader_pos',
                  'roberta_neg', 'roberta_neu', 'roberta_pos'],
            hue='Score',
            palette='tab10')
plt.show()
```

## Exemplificando com alguns comentários 

Comparando resultados dos modelos com comentarios nota 1 e 5

```{python}
results_df.query('Score == 1') \
    .sort_values('roberta_pos', ascending=False)['Text'].values[0]
```

```{python}
results_df.query('Score == 1') \
    .sort_values('vader_pos', ascending=False)['Text'].values[0]
```

```{python}
results_df.query('Score == 5') \
    .sort_values('vader_neg', ascending=False)['Text'].values[0]
```

```{python}
results_df.query('Score == 5') \
    .sort_values('roberta_neg', ascending=True)['Text'].values[0]
```